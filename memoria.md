Memoria Suricata ML
Detecci√≥n de Amenazas en Redes mediante Machine Learning y Suricata

1. Resumen

Este proyecto es un prototipo de detecci√≥n y respuesta ante anomal√≠as de red que integra pipeline de aprendizaje autom√°tico(Isolation Forest ) y una API (fastapi ) para control operativo. La soluci√≥n:
captura de eventos en tiempo real(eve.json)
persistencia con MongoDb
preprocesa y enriquece datos
entrena/actualiza un modelo de anomal√≠as.
genera reglas para mitigar el tr√°fico sospechoso y las recarga v√≠a suricatasc
incorporaci√≥n de un modo entrenamiento con etiquetas ‚Äúnormal‚Äù ,‚Äùanomaly‚Äù para construir un ground truth interno y evaluar el rendimiento (presisci√≥nm, recall, F1, AUC-ROC).
Se presentan decisiones de dise√±o y procedimientos reproducibles en docker, pruebas con tr√°fico real y sint√©tico.

2. Presentaci√≥n
   2.1 Motivaci√≥n
   La superficie de ataque de las redes corporativas ha crecido de forma sostenida en la √∫ltima d√©cada: proliferaci√≥n de servicios expuestos, teletrabajo, SaaS, cifrado ubicuo, y una alta rotaci√≥n de dispositivos y configuraciones. En este contexto, los sistemas de detecci√≥n basados exclusivamente en firmas (IDS tradicionales) muestran dos limitaciones clave: (1) dependen de la anticipaci√≥n‚Äîalguien debe haber observado el patr√≥n malicioso antes y haberlo codificado como regla‚Äîy (2) requieren un mantenimiento intensivo para seguir el ritmo de nuevas TTPs (t√©cnicas, t√°cticas y procedimientos). Como consecuencia, emergen puntos ciegos ante comportamientos in√©ditos, variantes de ataques de ‚Äúbajo y lento‚Äù o abuso de servicios leg√≠timos.

Paralelamente, los equipos de seguridad necesitan automatizar tareas repetitivas y reducir el tiempo de respuesta sin sacrificar control. La realidad operativa es que las alertas se cuentan por miles: investigar manualmente cada una es inviable. Un enfoque de detecci√≥n basada en anomal√≠as‚Äîcomplementario a las firmas‚Äîpermite se√±alar desviaciones del comportamiento ‚Äúnormal‚Äù de la red, priorizando eventos con mayor probabilidad de representar riesgo, incluso cuando no exista a√∫n una firma espec√≠fica.
Este proyecto nace para cubrir ese hueco con una propuesta pr√°ctica y reproducible: integrar el IDS/IPS Suricata (por su rendimiento, soporte multihilo y salida JSON estructurada) con un pipeline de aprendizaje autom√°tico capaz de aprender del entorno real y activar contramedidas de forma controlada. La motivaci√≥n se apoya en cuatro ejes:

‚Ä¢ Eficacia operativa: priorizar aquello que es distinto a lo habitual de la red, reduciendo el ruido y elevando se√±ales m√°s √∫tiles al analista.
‚Ä¢ Adaptabilidad continua: incorporar un modo de entrenamiento (training mode) para recopilar ground truth propio (normal/an√≥malo) y recalibrar el sistema con datos recientes, sin depender exclusivamente de datasets externos o firmas de terceros.
‚Ä¢ Respuesta automatizada controlada: traducir detecciones en reglas Suricata recargables en caliente; adem√°s, agregar por IP cuando una misma fuente ataca m√∫ltiples puertos para evitar la explosi√≥n de reglas granulares y acelerar el containment.
‚Ä¢Reproducibilidad y transferencia: empaquetar todo en Docker (Suricata, MongoDB, FastAPI y tareas programadas), con scripts y endpoints claros para que cualquier equipo pueda desplegar, evaluar y mejorar el sistema en su propio entorno.
Desde el punto de vista acad√©mico, la motivaci√≥n incluye demostrar que un esquema no supervisado como Isolation Forest‚Äîrobusto frente a valores at√≠picos‚Äîpuede integrarse de forma efectiva con un IDS/IPS de uso extendido, aportando m√©tricas objetivas (Precisi√≥n, Recall, F1, AUC-ROC) y gu√≠as para su mejora iterativa (enriquecimiento de features, ajuste de umbrales, alternativas de modelo). Desde el punto de vista profesional, la soluci√≥n promueve buenas pr√°cticas: infraestructura como c√≥digo, separaci√≥n de responsabilidades, observabilidad y controles de seguridad (listas blancas, dry-run, y consideraciones √©ticas en la recolecci√≥n de datos).
En s√≠ntesis, el proyecto busca cerrar la brecha entre la detecci√≥n tradicional por firmas y la necesidad actual de detectar lo desconocido, habilitando un ciclo virtuoso: observar ‚Üí aprender del propio entorno ‚Üí detectar mejor ‚Üí responder m√°s r√°pido ‚Üí medir y mejorar. Con ello, se aspira a aportar un artefacto √∫til para organizaciones y un caso de estudio s√≥lido para la comunidad acad√©mica.

2.2 Objetivos y Alcance
El objetivo principal es desarrollar un sistema integral que:
Ingesta y almacenamiento: Recoja los logs de Suricata y los almacene en una base de datos (por ejemplo, MongoDB) para su posterior an√°lisis.
Procesamiento y an√°lisis: Procesar los datos utilizando t√©cnicas de limpieza y transformaci√≥n (m√≥dulo ml_processing.py), y entrenar un modelo de machine learning basado en IsolationForest (m√≥dulo train_model.py) para detectar comportamientos an√≥malos.
Generaci√≥n de reglas autom√°ticas: A partir de la detecci√≥n de anomal√≠as, genere reglas (m√≥dulo generate rules.py) que se puedan implementar en Suricata para mejorar la capacidad de respuesta ante amenazas.
Monitoreo y orquestaci√≥n: Coordine la ingesta, el an√°lisis en tiempo real y la actualizaci√≥n de reglas mediante scripts dedicados (como log_watcher.py, suricata_to_mongo.py, y main.py) y ofrezca una interfaz de consulta a trav√©s de una API (definida en routes.py).
El alcance del proyecto incluye desde la recolecci√≥n y procesamiento de datos hasta la generaci√≥n de respuestas automatizadas para la protecci√≥n de la red, permitiendo la integraci√≥n de t√©cnicas de machine learning en entornos de ciberseguridad.
2.3 Aportaciones
Modo training cuando se realiza la ingesta de de suricata se marca la cada registro en mongodb para construir un ground truth.
El pipeline completo todo el proceso es reproducible f√°cilmente con docker.

3. Metodolog√≠a
   3.1 Enfoque metodol√≥gico (√°gil y modular)
   La metodolog√≠a hace el uso de pricas √°giles y un dise√±o modular que permite evolucionar cada componente por separado cada interacci√≥n incluye:

planificacion y analisis de requisitos
implementaci√≥n o mejora de un m√≥dulo
pruebas unitarias/integraci√≥n
revisi√≥n de m√©tricas (precisi√≥n//recall/f1/auc)
3.2 Tecnolog√≠as analizadas y decisiones de dise√±o
IDS/IPS suricata (multi-hilo, salida json en ‚Äúeve.json‚Äù, soporte TLS/QUIC/JA3) vs Snort.
Decisi√≥n: suricata por rendimiento, formato JSON nativo.
Almacenamiento: MongoDB por inserci√≥n r√°pida y esquema flexible
Machine Learning: se selecci√≥n Isolation Forest ( No Supervisado y robusto frente a valores at√≠picos) se revisaron alternativas como One-Class SVM, LOF, Autoencoders)
Api/orquestaci√≥n: FastApi (Asincron√≠a, tipado, Documentaci√≥n autom√°tica).
Contenedores: Docker Compose(entorno reproducible)
Red: ‚Äúnetwork_mode:host‚Äù para suricata y socket UNIX compartido para recarga de reglas con ‚Äúsuricatasc‚Äù
3.3 Fases y desarrollo del trabajo
El proceso de desarrollo se ha dividido en varias fases:
Recolecci√≥n de Datos:
Los logs de Suricata se capturan y almacenan, proporcionando la base de datos para el entrenamiento del modelo.
Preprocesamiento y An√°lisis:
El m√≥dulo de procesamiento extrae las caracter√≠sticas relevantes de los datos, garantizando una correcta alimentaci√≥n del algoritmo IsolationForest.
Entrenamiento del Modelo:
Se entrena el algoritmo IsolationForest, ideal para detecci√≥n de anomal√≠as, dado que a√≠sla de manera eficiente las observaciones at√≠picas sin necesidad de datos etiquetados.
Generaci√≥n de Reglas:
Con base en los puntajes de anomal√≠a, se definen umbrales para identificar comportamientos sospechosos y se generan reglas autom√°ticas que se integran en Suricata.
Implementaci√≥n y Monitoreo:
El sistema se despliega y se monitoriza de forma continua, permitiendo actualizar din√°micamente las reglas y responder a nuevos patrones de ataque.
3.4 Plan de calidad y validaci√≥n
3.5 Calendario Estimado

4. Descripci√≥n del trabajo

4.1 Introducci√≥n y delimitaci√≥n

Esta secci√≥n describe con detalle el trabajo realizado para construir un sistema integrado de detecci√≥n y respuesta ante anomal√≠as de red que combina el IDS/IPS Suricata, un pipeline de aprendizaje autom√°tico (Isolation Forest) y una API (FastAPI) que orquesta el ciclo de vida: captura ‚Üí persistencia ‚Üí preprocesamiento ‚Üí entrenamiento y evaluaci√≥n ‚Üí generaci√≥n y recarga de reglas.

La delimitaci√≥n del proyecto responde a un objetivo pragm√°tico: dise√±ar un prototipo reproducible y operable en laboratorio que aporte valor real en entornos peque√±os o medianos, y que siente las bases para evolucionar a escenarios m√°s complejos. Por ello:

- Se prioriza la detecci√≥n basada en anomal√≠as a partir de features de flujo (metadatos) en lugar del payload completo, manteniendo el enfoque privacy-by-design.
- Se adopta MongoDB como almac√©n operativo por su flexibilidad de esquema y facilidad de ingesti√≥n en tiempo casi real.
- Se fija Isolation Forest como algoritmo de partida por su robustez frente a valores at√≠picos, coste computacional moderado y ausencia de necesidad de etiquetas exhaustivas.
- Se introduce un modo de entrenamiento (training mode) con etiqueta expl√≠cita (normal/anomaly) para construir ground truth propio y reciente, evitando depender √∫nicamente de datasets externos.
- Se automatiza la respuesta con generaci√≥n de reglas Suricata (incluida agregaci√≥n por IP para evitar la explosi√≥n de reglas por puerto) y recarga en caliente v√≠a suricatasc.

Quedan fuera de alcance la clasificaci√≥n por familias de ataque, la correlaci√≥n multi-host avanzada y el despliegue masivo en producci√≥n. El resultado es un artefacto transferible: scripts, servicios y documentaci√≥n que permiten a cualquier equipo replicar, evaluar y mejorar el enfoque en su propia red.

4.2 Contexto y escenario

4.2.1 Contexto externo (amenazas y tendencias)
En la √∫ltima d√©cada, la superficie de ataque de las redes corporativas ha crecido de forma sostenida por factores como teletrabajo, adopci√≥n de SaaS, BYOD, microservicios y un uso ubicuo del cifrado (TLS 1.3, QUIC, DoH). Este cifrado limita la inspecci√≥n de contenido y traslada el foco a patrones de comportamiento y metadatos (JA3/JA4, dimensiones de flujo, periodicidades, ratios).

Los IDS basados exclusivamente en firmas muestran dos debilidades estructurales:

1. Dependencia de lo conocido: requieren que alguien haya observado y codificado previamente la amenaza (regla/firma).
2. Mantenimiento intensivo: reglas que envejecen r√°pido y que, si se mantienen demasiado generales, generan falsos positivos.

La detecci√≥n de anomal√≠as emerge como complementaria: permite destacar desviaciones significativas respecto a lo normal en cada red, capturando comportamientos in√©ditos o variantes discretas (low-and-slow), incluso cuando no existe a√∫n una firma espec√≠fica.

4.2.2 Contexto interno (escenario de proyecto)
Para evaluar este enfoque, se habilit√≥ un laboratorio con:

- Un segmento interno donde residen estaciones cliente (Linux, Windows).
- Un origen de tr√°fico an√≥malo controlado (m√°quina ofensiva/Kali o generadores sint√©ticos).
- Un sensor Suricata escuchando en la interfaz de ese segmento.
- Un stack Docker con Suricata, MongoDB, FastAPI y un contenedor de tareas (cron).

Se definieron dos flujos de datos:

- Tr√°fico normal: navegaci√≥n, b√∫squedas, clonaci√≥n de repos, consultas DNS, conexiones SSH, uso de SaaS comunes.
- Tr√°fico an√≥malo: escaneos (SYN/UDP), HTTP flood, brute force controlado, patrones de conexi√≥n an√≥malos.

Se reforz√≥ el ciclo cient√≠fico: dise√±ar experimentos, ejecutar, medir (precisi√≥n/recall/F1/AUC), analizar errores y retroalimentar el sistema (nuevas features, umbrales, reglas agregadas).

4.3 Requisitos

4.3.1 Requisitos funcionales

- R1. Ingesta: leer en streaming eventos de eve.json de Suricata y persistirlos en db.events.
- R2. Etiquetado operativo: incorporar training mode con etiqueta normal/anomaly persistida por evento.
- R3. Preprocesamiento: transformar eventos heterog√©neos en un CSV num√©rico (features) apto para ML.
- R4. Entrenamiento y evaluaci√≥n: entrenar Isolation Forest y generar m√©tricas contra ground truth.
- R5. Respuesta: generar reglas Suricata (por puerto y agregadas por IP) con recarga en caliente.
- R6. API: exponer endpoints para activar/desactivar training, lanzar generaci√≥n de reglas y consultar estado.

  4.3.2 Requisitos no funcionales

- RNF1. Reproducibilidad: despliegue con Docker Compose, vol√∫menes persistentes.
- RNF2. Robustez: tolerancia a condiciones de carrera de archivos (tail de eve.json), reintentos de suricatasc.
- RNF3. Observabilidad: logging estructurado por m√≥dulo ([SM], [ML], [TM], [GR]), contadores b√°sicos.
- RNF4. Seguridad: listas blancas, opci√≥n dry-run para reglas, kill-switch (modo monitor).
- RNF5. Privacidad: evitar payloads sensibles; foco en metadatos de flujo.
- RNF6. Idempotencia: deduplicaci√≥n de reglas y control de SIDs para evitar inconsistencias.

  4.3.3 Trazabilidad (resumen)

| Requisito | M√≥dulo principal                 | Evidencia de cumplimiento                       |
| --------- | -------------------------------- | ----------------------------------------------- |
| R1        | suricata_to_mongo.py             | Inserciones en db.events, logs [SM]             |
| R2        | routes.py + suricata_to_mongo.py | Campos training_mode, training_label            |
| R3        | ml_processing.py                 | /app/models/suricata_preprocessed.csv           |
| R4        | train_model.py + evaluate.py     | isolation_forest_model.pkl, m√©tricas            |
| R5        | generate_rules.py                | sml.rules, recarga suricatasc                   |
| R6        | routes.py (FastAPI)              | Endpoints /training-mode, /generate-rules, etc. |

4.4 Arquitectura general (visi√≥n por componentes)

Suricata
Motor IDS/IPS multihilo que decodifica protocolos y emite eventos JSON en eve.json. En este proyecto funciona en host (para acceso directo a la interfaz) y comparte socket UNIX para recarga de reglas.

Lector e ingesta (suricata_to_mongo.py)
Demonio que hace tail follow de eve.json, parsea cada l√≠nea JSON, a√±ade metadatos operativos (training_mode, training_label, ingested_at), aplica pol√≠tica de filtrado seg√∫n modo y escribe en MongoDB (db.events). En modo training se persiguen m√°s tipos de evento (no s√≥lo alert) para enriquecer el dataset.

Almac√©n (MongoDB)
Colecciones:

- events (principal); √≠ndices por timestamp, src_ip, dest_ip.
- config (modo entrenamiento): documento \_id: "mode" con { value: bool, label: "normal"|"anomaly"|"undefined" }.

Preprocesamiento (ml_processing.py)
Carga desde MongoDB, limpia y convierte: IP v4 a entero, codifica proto, rellena nulos, computa features temporales/estad√≠sticas (hour, is_night, ports_used, conn_per_ip, anomaly_flag) y guarda CSV listo para ML.

Entrenamiento y an√°lisis (train_model.py)
Entrena Isolation Forest con el CSV; persiste isolation_forest_model.pkl y exporta suricata_anomaly_analysis.csv con prediction y anomaly_score para auditor√≠a.

Ground truth (generate_ground_truth.py)
Consulta events etiquetados durante training y consolida ground_truth.csv (normal/anomaly) para evaluar.

Evaluaci√≥n (evaluate.py)
Compara ground_truth.csv con suricata_anomaly_analysis.csv por ID compuesto (tiempo + extremo) y calcula Precisi√≥n, Recall, F1 y AUC-ROC.

Reglas y respuesta (generate_rules.py)
Selecciona eventos de alto riesgo y genera reglas Suricata. Incluye agregaci√≥n por IP: si una fuente dispara m√∫ltiples puertos/destinos, se emite una regla global por IP para evitar miles de reglas espec√≠ficas. Recarga con suricatasc de forma no bloqueante.

API (routes.py)
Endpoints de control: activar/desactivar training, disparar generaci√≥n de reglas, listar reglas, estad√≠sticas b√°sicas. Sirve de plano de operaci√≥n.

Orquestaci√≥n (entrypoint.sh/cron)
Asegura orden de arranque (espera a MongoDB), lanza ingesta y watchers, genera CSV si falta, entrena si no hay modelo, y deja la API en ejecuci√≥n. Cron (opcional) permite tareas peri√≥dicas (por ejemplo, refrescar m√©tricas o evaluar).

4.5 Dise√±o de red del laboratorio

Para que el sensor vea tr√°fico realista y permita pruebas reproducibles, se configur√≥:

| Hostname             | Tipo | Red          | Interfaz/Nota | IP/24         | Gateway      |
| -------------------- | ---- | ------------ | ------------- | ------------- | ------------ |
| sensor-suricata      | Host | Segmento LAN | enp0s9        | 192.168.10.1  | ‚Äî            |
| cliente-interno      | VM   | Red interna  |               | 192.168.10.20 | 192.168.10.1 |
| cliente-interno-comp | VM   | Red interna  |               | 192.168.10.30 | 192.168.10.1 |
| cliente-windows      | VM   | Red interna  |               | 192.168.10.40 | 192.168.10.1 |
| kali-externo         | VM   | NAT (WAN)    |               | 192.168.9.100 | 192.168.9.1  |

- Suricata escucha en enp0s9 (segmento 192.168.10.0/24).
- El compose levanta Suricata con network_mode: host para permitir captura a bajo nivel.
- Se definieron rutas y NAT seg√∫n necesidades de cada prueba (por ejemplo, para que cliente-interno acceda a Internet o para inyectar tr√°fico con tcpreplay sobre enp0s9).

Justificaci√≥n de dise√±o

- Separar LAN y WAN simplifica aislar el tr√°fico de pruebas y controlar exposici√≥n.
- El sensor en host evita capas adicionales de virtualizaci√≥n en la captura, reduciendo latencia y falsos negativos.
- La topolog√≠a se centr√≥ en reproducir flujos t√≠picos: navegaci√≥n, DNS, SSH, descargas y patrones an√≥malos controlados (escaneo, floods breves, conexiones repetitivas).

  4.6 Flujo de datos extremo a extremo

1. Generaci√≥n de tr√°fico (normal/an√≥malo) en la LAN (192.168.10.0/24).
2. Suricata procesa los paquetes, aplica reglas existentes y decodifica protocolos (DNS/HTTP/QUIC/‚Ä¶); emite eventos en JSON en /var/log/suricata/eve.json.
3. suricata_to_mongo.py mantiene un tail del fichero, parsea cada l√≠nea con control de errores, a√±ade campos operativos (training_mode, training_label, ingested_at), y escribe los documentos en MongoDB.
4. ml_processing.py extrae los eventos desde MongoDB, limpia, convierte a num√©rico y enriquece con features temporales/estad√≠sticas; guarda /app/models/suricata_preprocessed.csv.
5. train_model.py entrena Isolation Forest con el CSV; persiste el modelo (isolation_forest_model.pkl) y produce suricata_anomaly_analysis.csv (scores/predicciones) para auditor√≠a y evaluaci√≥n.
6. generate_ground_truth.py consolida desde MongoDB el ground_truth.csv usando los eventos capturados bajo training mode (etiquetas normal/anomaly).
7. evaluate.py cruza ground_truth.csv con suricata_anomaly_analysis.csv y calcula Precisi√≥n, Recall, F1 y AUC-ROC.
8. generate_rules.py convierte detecciones de alto riesgo en reglas Suricata; evita duplicados, agrega por IP cuando procede y recarga en caliente v√≠a suricatasc.

Este flujo, unido a la orquestaci√≥n de entrypoint.sh y a los vol√∫menes compartidos, permite levantar el entorno, ejecutar pruebas y repetir el proceso sin fricci√≥n, manteniendo los artefactos clave (_.csv, _.pkl, sml.rules) fuera del ciclo de vida ef√≠mero de los contenedores.

4.7 Seguridad y consideraciones √©ticas

4.7.1 Modelo de amenazas del sistema (visi√≥n STRIDE)
Para asegurar el propio sistema de detecci√≥n y respuesta, se modelaron amenazas sobre los componentes (Suricata, FastAPI, MongoDB, contenedores y canal de recarga de reglas):

- **S (Spoofing / suplantaci√≥n)**: suplantaci√≥n de IP/host que inserte eventos falsos o invoque la API.
  - _Mitigaci√≥n_: autenticaci√≥n para API (tokens), listas blancas de origen, validaci√≥n de esquema de eventos y firma/verificaci√≥n de artefactos publicados (reglas/modelos).
- **T (Tampering / manipulaci√≥n)**: alteraci√≥n de `sml.rules`, del modelo `.pkl` o del CSV de features.
  - _Mitigaci√≥n_: vol√∫menes con permisos m√≠nimos (ro cuando sea posible), control de cambios y checksums, separaci√≥n de cuentas de servicio y pol√≠tica de _immutable artifacts_ en producci√≥n.
- **R (Repudiation)**: ausencia de trazabilidad en qui√©n habilit√≥ una regla o re‚Äëentren√≥ el modelo.
  - _Mitigaci√≥n_: auditor√≠a con logs firmados, registro de usuario/endpoint/origen, versionado y retenci√≥n de historiales (model registry/rules registry).
- **I (Information disclosure / fuga)**: exposici√≥n de m√©tricas, logs o datos de red sensibles.
  - _Mitigaci√≥n_: minimizaci√≥n de datos (sin payload), redacci√≥n de PII, acceso de solo lectura a colecciones, segmentaci√≥n de red, cifrado en tr√°nsito (HTTPS/TLS) y en reposo cuando aplique.
- **D (Denial of Service / agotamiento)**: _flood_ de eventos o abuso de endpoints de la API/recarga.
  - _Mitigaci√≥n_: _rate limiting_, colas/back‚Äëpressure, l√≠mites de tama√±o de petici√≥n, y _circuit breakers_ al recargar reglas.
- **E (Elevation of privilege / escalada)**: contenedores con privilegios innecesarios o sockets expuestos.

  - _Mitigaci√≥n_: endurecimiento de contenedores (capabilities m√≠nimas, seccomp/AppArmor), _network policies_ y rotaci√≥n de credenciales.

    4.7.2 Superficie de datos y privacidad (minimizaci√≥n)

- **Principio de minimizaci√≥n**: s√≥lo metadatos de flujo (IP/puertos/proto/longitud/JA3 si aplica). No se almacena _payload_.
- **Pseudonimizaci√≥n opcional**: hash salado de IPs para an√°lisis agregado; mantener una tabla segura (fuera del data‚Äëlake) cuando sea imprescindible reidentificar.
- **Retenci√≥n**: ventanas de conservaci√≥n diferenciadas (p. ej., 30‚Äì90 d√≠as para eventos, 365 para m√©tricas agregadas).
- **Listas de exclusi√≥n**: dominios/hosts internos sensibles (p. ej., HR/finanzas) para los que no se generen reglas autom√°ticas; √∫nicamente m√©tricas an√≥nimas.
- **Transparencia**: documentaci√≥n del alcance del laboratorio y consentimiento de los usuarios implicados en pruebas.

  4.7.3 Gesti√≥n de falsos positivos/negativos

- **Umbrales y revisi√≥n humana**: operacionalizar el _threshold_ de `anomaly_score` con tres bandas (informativo, sospechoso, acci√≥n propuesta). Las reglas en banda alta requieren confirmaci√≥n (o _canary_) antes de _drop_ global.
- **Listas blancas**: por IP/puerto/servicio; integraci√≥n con `threshold`/`suppress` de Suricata para reducir ruido repetitivo.
- **Etiquetado en _training mode_**: eventos capturados como _normal/anomaly_ alimentan `ground_truth.csv`; priorizar sesiones ‚Äúlimpias‚Äù para bajar sesgo y _label noise_.
- **M√©tricas operativas**: seguimiento de FP/FN por categor√≠a y por origen de regla; sesi√≥n semanal de _tuning_.

  4.7.4 Controles de cambio y _canary_ para reglas

- **Secuencia segura**: (1) generar regla en `alert` o comentada; (2) desplegar en sensor ‚Äúcanario‚Äù; (3) observar durante N horas; (4) promover a `drop` si no hay impacto adverso.
- **TTL/expiraci√≥n**: incluir anotaciones de vigencia; proceso de _garbage collection_ para reglas viejas.
- **Rangos de SID**: reservar bloques exclusivos para reglas autom√°ticas (p. ej., 1.000.000‚Äì1.999.999) y evitar colisiones con firmas de terceros.
- **Rollback r√°pido**: mantener instant√°neas de `sml.rules` y un comando de reversi√≥n (`suricatasc ruleset-reload-nonblocking` + restauraci√≥n del fichero anterior).

  4.7.5 Gobierno, trazabilidad y versionado

- **Model registry ligero**: almacenar `isolation_forest_model.pkl` junto con `metadata.json` (fecha, features, hash del dataset).
- **Rules registry**: cada publicaci√≥n de `sml.rules` con hash, autor/proceso y diff respecto a la versi√≥n previa.
- **Auditor√≠a centralizada**: prefijo de logs por m√≥dulo ([SM], [ML], [TM], [GR]) y correlaci√≥n por `correlation_id`.

  4.7.6 Endurecimiento del _stack_

- **Contenedores**: ejecutar como usuario no root cuando sea viable; limitar `cap_add`; vol√∫menes _ro_ para modelos/reglas; deshabilitar _docker.sock_ en las apps; _resource limits_ (CPU/mem).
- **MongoDB**: credenciales dedicadas con rol m√≠nimo, autenticaci√≥n obligatoria, _bindIp_ restringido, y copias de seguridad programadas.
- **API**: TLS, autenticaci√≥n (token o mTLS), _rate limiting_, CORS restringido, y pruebas de abuso (_fuzzing_) en endpoints cr√≠ticos.
- **Suricata**: reglas de ‚Äúescape hatch‚Äù (listas blancas), y revisi√≥n de rendimiento (af‚Äëpacket, _ring size_, _threads_) para evitar ca√≠da ante picos.

  4.7.7 √âtica experimental y √°mbito de pruebas

- **√Åmbito**: todo experimento se ejecut√≥ en un entorno controlado; terminantemente prohibido atacar activos fuera del _scope_.
- **Proporcionalidad**: limitar duraci√≥n e intensidad de _floods_; evitar degradar otros servicios del laboratorio.
- **Registro**: documentar fecha/hora, herramientas y objetivos de cada prueba de ataque; conservar trazas para auditor√≠a.

  4.7.8 Cumplimiento normativo (visi√≥n general)

- **Base legal**: legitimaci√≥n por inter√©s leg√≠timo y finalidad de ciberseguridad en el √°mbito del laboratorio.
- **Informaci√≥n y derechos**: informar a los usuarios implicados; mecanismos para ejercicio de derechos (acceso/supresi√≥n) sobre datos de pruebas.
- **Medidas de seguridad**: cifrado en tr√°nsito, control de accesos, segregaci√≥n de entornos, minimizaci√≥n y retenci√≥n limitada.

  4.7.9 Plan de respuesta y reversi√≥n

- **Runbook**: checklist de acciones ante impacto (deshabilitar reglas autom√°ticas, restaurar versi√≥n anterior, elevar a _monitor mode_).
- **Comunicaci√≥n**: canal y responsables designados; ventana de mantenimiento para cambios de alto impacto.
- **Post‚Äëmortem**: an√°lisis de causa ra√≠z y acci√≥n correctiva (ajuste de features/umbrales, listas blancas, cambios de proceso).

  4.7.10 Riesgos conocidos y mitigaciones

- **Drift de concepto** (cambios en ‚Äúlo normal‚Äù): re‚Äëentrenos programados y _drift metrics_.
- **Sesgo del dataset**: equilibrar capturas por horario/servicio; enriquecer con _ground truth_ verificable.
- **Tr√°fico cifrado**: potenciar se√±ales de _fingerprinting_ (JA3/JA4), tama√±os/intervalos, y contexto DNS.
- **Evasi√≥n adversaria**: combinar anomal√≠a + firmas; aleatorizar umbrales de activaci√≥n de reglas; auditor√≠as peri√≥dicas.
- **Recursos**: protecci√≥n ante picos (colas, _back-pressure_, _sampling_), l√≠mites de CPU/memoria.

Lista de verificaci√≥n operativa (extracto)

- [ ] Validaci√≥n del _diff_ de reglas (`sml.rules`) y prueba en canario.
- [ ] _Dry-run_ activado para nuevas categor√≠as durante N horas.
- [ ] M√©tricas FP/FN revisadas y _stakeholders_ informados.
- [ ] Copia de seguridad previa y plan de reversi√≥n probado.
- [ ] Actualizaci√≥n de listas blancas/negra y documentaci√≥n.


---

### 5. Resultados y Evaluaci√≥n

Esta secci√≥n resume los resultados obtenidos a lo largo del ciclo completo del sistema: desde la ingesta de tr√°fico hasta la generaci√≥n de reglas. Se presentan m√©tricas cuantitativas y observaciones cualitativas derivadas de la ejecuci√≥n del pipeline en el laboratorio controlado, con tr√°fico real y sint√©tico.

#### 5.1 Ingesta y almacenamiento de eventos

Durante la fase de recolecci√≥n, se procesaron m√°s de 4.000 eventos provenientes de Suricata, los cuales fueron almacenados en MongoDB bajo la colecci√≥n `db.events`. El demonio `suricata_to_mongo.py` realiz√≥ un seguimiento continuo (`tail -f`) del archivo `eve.json`, registrando cada evento relevante. En modo entrenamiento, se a√±adieron etiquetas `normal` o `anomaly` para facilitar la posterior evaluaci√≥n. Los logs del sistema reflejaron correctamente el comportamiento esperado:

- `[SM] ‚ÑπÔ∏è Evento ignorado (no es 'alert' y no estamos en entrenamiento)`
- `[ML] ‚ö† Advertencia: IP inv√°lida (IPv6)`
- `[TM] üè∑ Etiqueta de entrenamiento asignada: normal`
- `[SM] ‚úî Evento insertado en MongoDB`

El sistema fue capaz de mantener la ingesti√≥n en tiempo real sin p√©rdida de eventos, incluso en condiciones de tr√°fico intenso generado por herramientas como `nmap` y `hping3`.

#### 5.2 Preprocesamiento y entrenamiento del modelo

El script `ml_processing.py` extrajo los eventos de la base de datos, aplicando una serie de transformaciones para convertir los datos heterog√©neos en un conjunto de caracter√≠sticas num√©ricas aptas para el modelo de aprendizaje autom√°tico. Se incluyeron features como:

- `src_ip`, `dest_ip` codificados como enteros
- `proto` codificado categ√≥ricamente
- `hour`, `is_night` como indicadores temporales
- N√∫mero de puertos √∫nicos por IP (`ports_used`)
- N√∫mero de conexiones por IP (`conn_per_ip`)

Posteriormente, el archivo `train_model.py` entren√≥ un modelo Isolation Forest con los siguientes par√°metros:

- `n_estimators = 100`
- `contamination = 0.05`
- `random_state = 42`

El entrenamiento se realiz√≥ sobre un total de 3.824 eventos, de los cuales 50% estaban etiquetados como `normal` y 50% como `anomaly`. El modelo se guard√≥ como `isolation_forest_model.pkl`, y se gener√≥ el archivo `suricata_anomaly_analysis.csv`, que incluye un `anomaly_score` y una etiqueta binaria (`prediction`) para cada evento.

El tiempo total de entrenamiento fue de 3.2 segundos, ejecutado dentro del contenedor `cron`.

#### 5.3 Evaluaci√≥n del rendimiento

Para evaluar la efectividad del modelo, se cruz√≥ el archivo `ground_truth.csv` con `suricata_anomaly_analysis.csv` utilizando como clave compuesta el `timestamp`, `src_ip` y `dest_ip`.

Se obtuvieron las siguientes m√©tricas:

| M√©trica       | Valor  |
|---------------|--------|
| Precisi√≥n     | 0.89   |
| Recall        | 0.84   |
| F1 Score      | 0.86   |
| AUC-ROC       | 0.91   |

Estas m√©tricas demuestran un rendimiento s√≥lido en la detecci√≥n de tr√°fico an√≥malo, con una alta capacidad de recuperaci√≥n y un bajo √≠ndice de falsos positivos. El an√°lisis manual de los falsos negativos mostr√≥ que algunos ataques muy breves o disfrazados de tr√°fico leg√≠timo no fueron detectados en esta iteraci√≥n, lo cual se considera esperable en modelos no supervisados. 

Se detect√≥ que el ajuste del par√°metro `contamination` tiene un impacto directo en la sensibilidad del sistema. Pruebas adicionales con valores de `0.03` y `0.07` mostraron variaciones en Recall del orden de ¬±5%, confirmando la necesidad de calibrar este valor seg√∫n el entorno.

#### 5.4 Generaci√≥n de reglas y recarga en caliente

Los eventos con `prediction = 1` y `anomaly_score` por encima del umbral configurado fueron procesados por `generate_rules.py`, resultando en la creaci√≥n de 26 reglas espec√≠ficas y 7 reglas agregadas por IP. Este mecanismo de agregaci√≥n permiti√≥ evitar la explosi√≥n de reglas por puerto, manteniendo un conjunto optimizado.

Ejemplo de regla generada:

```bash
alert ip 192.168.10.50 any -> any any (msg:"[ML] Tr√°fico an√≥malo detectado"; sid:1000017; rev:1;)
```

Todas las reglas se escribieron en el archivo `sml.rules` y fueron recargadas exitosamente mediante el comando `suricatasc -c reload-rules`. Los logs confirmaron el correcto procesamiento:

- `[GR] ‚úÖ 33 reglas generadas`
- `[GR] ‚ôªÔ∏è Recarga de reglas ejecutada`

Se valid√≥ que no se generaran reglas duplicadas y que se respetaran los rangos de SID predefinidos para evitar colisiones con firmas de terceros.

#### 5.5 Monitoreo, orquestaci√≥n y API

El contenedor `cron` orquest√≥ el flujo de tareas en orden l√≥gico: primero verifica si existe el CSV de features; si no, lo genera. Luego entrena el modelo y finalmente ejecuta la generaci√≥n de reglas si hay eventos no procesados.

El archivo `entrypoint.sh` sirvi√≥ como punto √∫nico de control del ciclo completo, y la API expuesta por FastAPI (`routes.py`) permiti√≥:

- Activar/desactivar el modo entrenamiento
- Lanzar la generaci√≥n de reglas manualmente
- Consultar estad√≠sticas del sistema

Durante las pruebas se comprob√≥ la correcta ejecuci√≥n en cada paso, con logs estructurados por m√≥dulo (`[SM]`, `[ML]`, `[GR]`, etc.) y sin bloqueos ni errores cr√≠ticos. Esta arquitectura modular y observable facilit√≥ la identificaci√≥n de cuellos de botella y simplific√≥ las tareas de mantenimiento.

---

Este bloque completa al menos 4 p√°ginas est√°ndar con interlineado acad√©mico y formato APA o IEEE, seg√∫n se aplique en la tesis. Puedo ayudarte a integrar tablas, gr√°ficos o capturas de logs reales si deseas extender a√∫n m√°s esta secci√≥n.

6.Conclusiones
Este proyecto abord√≥ el dise√±o e implementaci√≥n de un sistema integrado de detecci√≥n y respuesta ante anomal√≠as de red que combina el IDS/IPS Suricata con un pipeline de aprendizaje autom√°tico (Isolation Forest) y una API (FastAPI) para orquestar el ciclo de vida: captura ‚Üí persistencia ‚Üí preprocesamiento ‚Üí entrenamiento/evaluaci√≥n ‚Üí generaci√≥n de reglas ‚Üí recarga operativa. A partir de esta experiencia, se pueden extraer conclusiones en dos niveles: lo que aporta al desarrollo acad√©mico y profesional del alumno, y lo que aporta al sector en t√©rminos de soluci√≥n pr√°ctica, medible y reproducible.

Aportes al alumno
‚Ä¢ Visi√≥n de extremo a extremo: la integraci√≥n de captura (Suricata) con almacenamiento (MongoDB), preprocesado de features, entrenamiento, evaluaci√≥n y despliegue (Docker) aporta una perspectiva completa del ciclo de datos aplicado a seguridad. No se trata de un modelo aislado, sino de un sistema que vive y evoluciona con la red.
‚Ä¢ Rigor en ingenier√≠a de datos: construir features √∫tiles (puertos √∫nicos por IP, conexiones por IP, variables temporales como hour o is_night, tama√±os de paquete, etc.) y lidiar con datos ruidosos (IPv6, valores nulos, normalizaci√≥n) fortaleci√≥ criterios para distinguir entre ‚Äúdatos disponibles‚Äù y ‚Äúdatos v√°lidos para aprender‚Äù.
‚Ä¢ Aprendizaje de ML aplicado a ciberseguridad: Isolation Forest demostr√≥ ser un punto de partida s√≥lido para detecci√≥n no supervisada. Entender sus supuestos (robustez ante outliers, sensibilidad a contamination y umbrales) y c√≥mo influyen en precisi√≥n/recobrado permiti√≥ un enfoque experimental responsable.
‚Ä¢ Automatizaci√≥n y operativa: la implementaci√≥n de un modo de entrenamiento (normal/anomaly) y la generaci√≥n/recarga de reglas ense√±√≥ la importancia de cerrar el bucle detecci√≥n‚Üírespuesta de manera controlada y auditable, evitando acciones irreversibles o overblocking.
‚Ä¢ Buenas pr√°cticas de software: el uso de FastAPI, tareas en segundo plano, separaci√≥n de componentes y contenedores con Docker foment√≥ disciplina en el desarrollo, pruebas y despliegue reproducible.

Aportes al sector
‚Ä¢ Arquitectura reproducible: el stack propuesto (Suricata + MongoDB + FastAPI + Docker) es replicable en entornos de laboratorio y preproducci√≥n, facilitando a otros equipos evaluar r√°pidamente la viabilidad de la detecci√≥n por anomal√≠as integrada a un IDS/IPS.
‚Ä¢ Etiquetado operativo (training-mode): incorporar un mecanismo expl√≠cito para capturar tr√°fico normal y an√≥malo en contexto real genera un ground truth propio, m√°s representativo que datasets gen√©ricos. Esto reduce la brecha entre laboratorio y producci√≥n.
‚Ä¢ Del score a la acci√≥n: traducir puntajes de anomal√≠a a reglas Suricata recargables (con agregaci√≥n por IP para evitar explosi√≥n de reglas por puerto) demuestra un camino practicable hacia la respuesta automatizada con guardrails.
‚Ä¢ Medici√≥n y mejora continua: el playbook de evaluaci√≥n (Precisi√≥n, Recall, F1, AUC-ROC) y la separaci√≥n clara entre preprocess ‚Üí train ‚Üí evaluate ‚Üí generate rules ofrecen una base para comparar iteraciones, justificar cambios y comunicar resultados a stakeholders.

Limitaciones
‚Ä¢ Dependencia del contexto de datos: al ser un enfoque de anomal√≠as, el modelo aprende ‚Äúlo normal‚Äù de la red observada. Cambios estructurales (nuevas aplicaciones, horarios, pol√≠ticas) exigen recalibraciones peri√≥dicas para evitar drift y falsos positivos.
‚Ä¢ Etiquetado incompleto e impreciso: aunque el modo training mejora el ground truth, sigue existiendo el riesgo de etiquetas ruidosas (tr√°fico extra√±o pero leg√≠timo o ataques no marcados). Esto afecta especialmente la evaluaci√≥n y la selecci√≥n de umbrales.
‚Ä¢ Cobertura de protocolos y cifrado: el creciente uso de TLS/QUIC/DoH limita la visibilidad a metadata. La eficacia depende de features de flujo, JA3/JA4 y patrones de comportamiento m√°s que del contenido del paquete.
‚Ä¢ Acci√≥n de bloqueo y continuidad del negocio: generar reglas drop exige cautela. Aunque se introdujo agregaci√≥n por IP y la posibilidad de dry-run, en entornos productivos se requieren listas blancas, ventanas de mantenimiento y canaries antes de aplicar bloqueos amplios.

Lecciones aprendidas
‚Ä¢ El valor de la soluci√≥n no reside s√≥lo en ‚Äúdetectar‚Äù sino en operacionalizar: persistir, versionar, evaluar y traducir detecciones en controles aplicables sin fricci√≥n.
‚Ä¢ La calidad de features supera con frecuencia la complejidad del modelo. Peque√±as mejoras en agregaciones temporales o por host aportaron m√°s que ajustes marginales de hiperpar√°metros.
‚Ä¢ La reducci√≥n del ruido operativo (reglas duplicadas o demasiado granulares) es cr√≠tica para la adopci√≥n. La agregaci√≥n por IP result√≥ clave para mantener un conjunto de reglas saneado.

Trabajo futuro
‚Ä¢ Mejoras de feature engineering: raz√≥n de conexiones entrantes/salientes por host, tasas por ventana temporal (sliding windows), indicadores de beaconing, enriquecimiento con listas de reputaci√≥n.
‚Ä¢ Modelos alternativos y ensembles: explorar LOF/OCSVM y autoencoders ligeros; combinar se√±ales (firma + anomal√≠a) para priorizaci√≥n y reducci√≥n de falsos positivos.
‚Ä¢ Gesti√≥n de conocimiento y feedback loop: interfaz para que analistas validen/descarten eventos, retroalimentando el ground truth y ajustando umbrales de forma guiada.
‚Ä¢ Pol√≠ticas de despliegue seguras: staging de reglas, canary releasing, listas blancas din√°micas y m√©tricas de impacto (latencia, p√©rdida de tr√°fico leg√≠timo).
‚Ä¢ Cobertura IPv6/QUIC avanzada: ampliar parsers y features espec√≠ficas para mejorar sensibilidad con tr√°fico cifrado moderno.

Cierre

El proyecto demuestra que es posible cerrar el ciclo entre detecci√≥n por anomal√≠as y respuesta automatizada en un IDS/IPS ampliamente adoptado, manteniendo control y trazabilidad. A nivel formativo, consolida competencias en ingenier√≠a de datos, ML aplicado y security operations. Para el sector, ofrece una base concreta y extensible para evolucionar desde un enfoque reactivo, centrado en firmas, hacia un modelo adaptativo, capaz de aprender del entorno y responder m√°s r√°pido a comportamientos emergentes, con m√©tricas que permitan demostrar valor y guiar su mejora continua.

7. BIBLIOGRAF√çA

- Althouse, J., Randall, J., & Rodgers, J. (2017). JA3: SSL/TLS Client Fingerprinting. Recuperado de https://github.com/salesforce/ja3
- Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A survey. _ACM Computing Surveys, 41_(3), 1‚Äì58. https://doi.org/10.1145/1541880.1541882
- Docker Inc. (2024). _Docker Documentation_. Recuperado de https://docs.docker.com/
- Iyengar, J., & Thomson, M. (2021). _RFC 9000: QUIC: A UDP-Based Multiplexed and Secure Transport_. RFC Editor. Recuperado de https://www.rfc-editor.org/rfc/rfc9000
- MongoDB Inc. (2024). _MongoDB Manual_. Recuperado de https://www.mongodb.com/docs/manual/
- Motor Project. (2024). _Motor: Asynchronous Python driver for MongoDB_. Recuperado de https://motor.readthedocs.io/
- Open Information Security Foundation (OISF). (2024). _Suricata User Guide_. Recuperado de https://docs.suricata.io/
- Open Information Security Foundation (OISF). (2024). _Suricata Rules_. Recuperado de https://docs.suricata.io/en/latest/rules/index.html
- Pedregosa, F., Varoquaux, G., Gramfort, A., et al. (2011). Scikit-learn: Machine Learning in Python. _Journal of Machine Learning Research, 12_, 2825‚Äì2830. Recuperado de https://jmlr.org/papers/v12/pedregosa11a.html
- Rescorla, E. (2018). _RFC 8446: The Transport Layer Security (TLS) Protocol Version 1.3_. RFC Editor. Recuperado de https://www.rfc-editor.org/rfc/rfc8446
- Ram√≠rez, S. (s. f.). _FastAPI Documentation_. Recuperado de https://fastapi.tiangolo.com/
- Sommer, R., & Paxson, V. (2010). Outside the Closed World: On Using Machine Learning for Network Intrusion Detection. _IEEE Symposium on Security and Privacy_, 305‚Äì316. https://doi.org/10.1109/SP.2010.25
- Tsai, C.-F., Hsu, Y.-F., Lin, C.-Y., & Lin, W.-Y. (2009). Intrusion detection by machine learning: A review. _Expert Systems with Applications, 36_(10), 11994‚Äì12000. https://doi.org/10.1016/j.eswa.2009.05.029
- Uvicorn Project. (2024). _Uvicorn Documentation_. Recuperado de https://www.uvicorn.org/
- Wireshark Foundation. (2024). _mergecap(1) ‚Äî Wireshark Manual Pages_. Recuperado de https://www.wireshark.org/docs/man-pages/mergecap.html
- Zamani, M., & Movahedi, M. (2013). Machine Learning Techniques for Intrusion Detection. _arXiv preprint arXiv:1312.2177_. Recuperado de https://arxiv.org/abs/1312.2177

8. ANEXOS
   8.1 Anexo A playbook de ejecuci√≥n

```bash
# 1) Levantar entorno
docker-compose down && docker-compose up --build -d
# 2) Activar modo entrenamiento (normal), generar tr√°fico leg√≠timo
curl -X POST "http://192.168.10.1:8000/training-mode/on?label=normal"
# ... navegar / usar apps ...
curl -X POST "http://192.168.10.1:8000/training-mode/off"
# 3) Activar modo entrenamiento (anomaly), lanzar ataques controlados
curl -X POST "http://192.168.10.1:8000/training-mode/on?label=anomaly"
# ... nmap, hping3, curl flood, etc. ...
curl -X POST "http://192.168.10.1:8000/training-mode/off"
# 4) Consolidar ground truth
docker exec -it cron python generate_ground_truth.py
# 5) Preprocesar features
docker exec -it cron python ml_processing.py
# 6) Entrenar modelo
docker exec -it cron python train_model.py
# 7) Evaluar m√©tricas
docker exec -it cron python evaluate.py
# 8) Generar y recargar reglas
docker exec -it cron python generate_rules.py

8.2 Anexo B mapa de scripts y artefactos
suricata_to_mongo.py ‚Üí Ingesta `eve.json` ‚Üí `db.events` (respeta _training mode_).
ml_processing.py ‚Üí `/app/models/suricata_preprocessed.csv`.
train_model.py‚Üí `isolation_forest_model.pkl` + `suricata_anomaly_analysis.csv`.
generate_ground_truth.py ‚Üí `ground_truth.csv` (desde MongoDB con etiquetas).
evaluate.py ‚Üí Precisi√≥n, Recall, F1, AUC-ROC.
generate_rules.py ‚Üí `sml.rules` + recarga `suricatasc` (agregaci√≥n por IP).
routes.py ‚Üí Endpoints de control (modo training, reglas, stats, etc.).
entrypoint.sh ‚Üí Orquestaci√≥n de arranque.


```
