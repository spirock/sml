"""
üîç train_model.py

üìå Funci√≥n principal:
    Entrenar un modelo de Machine Learning (Isolation Forest) utilizando datos preprocesados por `ml_processing.py`.
    El objetivo es identificar patrones an√≥malos en el tr√°fico de red observado por Suricata.

üéØ Objetivo:
    Cargar los datos procesados desde `suricata_preprocessed.csv`, entrenar un modelo de detecci√≥n de anomal√≠as,
    guardar el modelo entrenado (`isolation_forest_model.pkl`) y generar un archivo con los resultados y predicciones
    (`suricata_anomaly_analysis.csv`).

üîó Dependencias y v√≠nculos:
    - Entrada: `/app/models/suricata_preprocessed.csv` (generado por ml_processing.py)
    - Salida:
        - `/app/models/isolation_forest_model.pkl` ‚Üí Modelo entrenado
        - `/app/models/suricata_anomaly_analysis.csv` ‚Üí Resultados de score y predicci√≥n por evento
    - Librer√≠as: scikit-learn (IsolationForest), pandas, numpy, joblib

üìù Requisitos previos:
    Asegurarse de haber ejecutado `ml_processing.py` para que los datos est√©n preparados antes de entrenar.

"""
import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest
import joblib
import os
from constants import ANOMALY_PREDICTION

# Rutas de los archivos
DATA_PATH = "/app/models/suricata_preprocessed.csv"
MODEL_DIR = "/app/models"
MODEL_PATH = os.path.join(MODEL_DIR, "isolation_forest_model.pkl")

# Verificar si el archivo de datos existe
if not os.path.exists(DATA_PATH):
    print(f"[TM]‚ùå No se encontr√≥ el archivo {DATA_PATH}. Aseg√∫rate de ejecutar el preprocesamiento antes.")
    exit(1)

df = pd.read_csv(DATA_PATH)
df_original = df.copy()

# Verificar si hay valores NaN o datos faltantes
if df.isnull().values.any():
    print("[TM] ‚ö† Advertencia: Se encontraron valores NaN en los datos. Rellenando con ceros.")
    df.fillna(0, inplace=True)

# Asegurar que todas las columnas sean num√©ricas
for col in df.columns:
    df[col] = pd.to_numeric(df[col], errors="coerce")

# Si todav√≠a hay NaN, reemplazarlos con ceros
df.fillna(0, inplace=True)

label_column = "label_num"
X = df.drop(columns=["timestamp", "src_ip", "dest_ip", "label_text", label_column], errors="ignore")
# Nota: event_id no se incluye en el entrenamiento ya que representa un identificador √∫nico de MongoDB (ObjectId),
# no aporta valor predictivo y podr√≠a sesgar el modelo. Se conserva solo en los resultados para trazabilidad.
y = df[label_column] if label_column in df.columns else None

# Crear la carpeta models/ si no existe
os.makedirs(MODEL_DIR, exist_ok=True)

# Verificar que no haya columnas vac√≠as antes de entrenar
if X.shape[1] == 0:
    print("[TM] ‚ùå Error: No hay columnas en los datos despu√©s del preprocesamiento.")
    exit(1)

# Entrenar el modelo Isolation Forest
print("[TM] üîç Entrenando modelo Isolation Forest...")
model = IsolationForest(contamination=0.05, random_state=42)  # 5% de tr√°fico an√≥malo

try:
    model.fit(X)
    # Guardar el modelo en la carpeta persistente
    joblib.dump(model, MODEL_PATH)
    print(f"[TM] ‚úÖ Modelo entrenado y guardado en {MODEL_PATH}")

    # **Evaluaci√≥n del Modelo**
    print("\n [TM] üìä Evaluando el modelo...")

    # Obtener los puntajes de anomal√≠a
    anomaly_scores = model.decision_function(X)
    predictions = model.predict(X)
    # Convertimos la predicci√≥n a binaria para consistencia (1 = anomal√≠a, 0 = normal)
    result_df = pd.DataFrame()
    # Mantener campos clave
    for col in ["proto", "src_port", "dest_port", "alert_severity", "packet_length",
                "hour", "is_night", "ports_used", "conn_per_ip", "event_id",
                "src_ip", "dest_ip", "timestamp"]:
        if col in df_original.columns:
            result_df[col] = df_original[col]
    # A√±adir resultados del modelo
    result_df["anomaly_score"] = anomaly_scores
    result_df["prediction"] = predictions
    # Convertimos la predicci√≥n a binaria para consistencia (1 = anomal√≠a, 0 = normal)
    result_df["is_anomaly"] = (predictions == ANOMALY_PREDICTION).astype(int)
    # A√±adir columna label en formato texto ("anomaly"/"normal"), como en otros scripts
    result_df["label"] = result_df["prediction"].apply(lambda x: "anomaly" if x == ANOMALY_PREDICTION else "normal")
    # Contar anomal√≠as detectadas
    total_anomalies = (predictions == ANOMALY_PREDICTION).sum()
    print(f"[TM] ‚ö† Total de anomal√≠as detectadas: {total_anomalies} de {len(X)} eventos.")
    # Guardar en CSV
    result_file = "/app/models/suricata_anomaly_analysis.csv"
    result_df.to_csv(result_file, index=False)
    print(f"[TM] ‚úÖ Resultados guardados en {result_file}")
    # Mostrar conteo de instancias por etiqueta
    print(result_df["label"].value_counts())
except Exception as e:
    print(f"[TM] ‚ùå Error al entrenar el modelo: {e}")
